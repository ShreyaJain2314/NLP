# NLP

#Spell-Checker

It opens a file located at the specified filepath (assumed to be a path to a text file) using a with statement, reading it in 'r' (read) mode.

It reads all the lines from the opened file and stores them in the lines list.

It initializes an empty list called words to store words extracted from the lines of the file.

It processes each line in the lines list, converts the line to lowercase, and uses regular expressions (re.findall) to extract words (sequences of word characters) from each line. These extracted words are added to the words list.

It prints the total number of words in the file (len(words)).

It creates a vocabulary list called vocab by converting the words list to a set and then back to a list. This ensures that each word is unique in the vocabulary.

It prints the total number of unique words in the vocabulary (len(vocab)).

It initializes an empty dictionary called word_probability.

It calculates the probability of each word in the vocabulary by dividing the count of that word in the words list by the total number of words. The results are stored in the word_probability dictionary.

It defines a function split(w) that splits a word into all possible pairs of left and right substrings. For example, split("loave") will return a list of pairs like [( '', 'loave' ), ( 'l', 'oave' ), ( 'lo', 'ave' ), ( 'loa', 've' ), ( 'loav', 'e' ), ( 'loave', '' )].

It defines four more functions (delete, swap, replace, and insert) that take a word as input and generate variations of that word by performing different operations (deleting a character, swapping adjacent characters, replacing a character, or inserting a character).

It defines an edit function that combines the variations generated by the delete, swap, replace, and insert functions for a given word.

It calls the edit function with the input word "loave" and stores the suggested variations in the suggested_words variable.

It initializes an empty list called output and filters the suggested words to keep only those that exist in the word_probability dictionary. The filtered words and their probabilities are added to the output list.

It creates a Pandas DataFrame (df) to display the suggested words along with their probabilities. The DataFrame is sorted by probability in ascending order.

Finally, it defines a spell_check function that takes a word and an optional count parameter. It generates suggestions for the input word and returns the top count suggestions based on their probabilities. In this case, it calls spell_check with the input word "cresh" and returns a list of suggested words with their probabilities.

Overall, this code demonstrates a basic spell-checking mechanism using simple edit operations and word probabilities based on the provided text file.


#Embeddings

The embeddings folder shows the working of word2vec and Doc2v on the train and test dataset.
